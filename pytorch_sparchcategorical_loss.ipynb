{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_sparchcategorical_loss.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGjRmijsaXJ3"
      },
      "source": [
        "### Necessary Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOyGrPT5ASDc"
      },
      "source": [
        "# Import necessary packages\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPuuTDEfAfDy"
      },
      "source": [
        "import os\n",
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KO3ixK4P_S9l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cb2cc4a-685d-4dc0-da50-f27ab4313ed8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLdtrS4zaeEs"
      },
      "source": [
        "### Download The Dataset & Define The Transforms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZD2NGz2Ak6w"
      },
      "source": [
        "### Run this cell\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                 transforms.Normalize((0.5,), (0.5,)),\n",
        "                              ])\n",
        "\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('/content/drive/My Drive/handwritten-digit-recognition-master/MNiST/', download=True, train=True, transform=transform)\n",
        "valset = datasets.MNIST('/content/drive/My Drive/handwritten-digit-recognition-master/MNiST/', download=True, train=False, transform=transform)\n",
        "testset = datasets.MNIST('/content/drive/My Drive/handwritten-digit-recognition-master/MNiST/', download=True, train=False,transform = transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=64*2, shuffle=True)\n",
        "testloader= torch.utils.data.DataLoader(testset,batch_size=64*2, shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WJXInzQGcAy"
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "# Layer details for the neural network\n",
        "input_size = 784\n",
        "hidden_sizes = [128, 64]\n",
        "output_size = 10\n",
        "\n",
        "# Build a feed-forward network\n",
        "class MnistModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear1 = nn.Linear(input_size,hidden_sizes[0])\n",
        "    self.activation1 = nn.ReLU()\n",
        "    self.linear2 = nn.Linear(hidden_sizes[0],hidden_sizes[1])\n",
        "    self.activation2 = nn.ReLU()\n",
        "    self.linear3 = nn.Linear(hidden_sizes[1],output_size)\n",
        "    self.activation3= nn.Softmax()\n",
        "    self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "  def forward(self,xb):\n",
        "    xb = xb.reshape(-1,784)\n",
        "    x = self.linear1(xb)\n",
        "    x = self.activation1(x)\n",
        "    x = self.linear2(x)\n",
        "    x = self.activation2(x)\n",
        "    x = self.dropout(x)\n",
        "    x = self.linear3(x)\n",
        "    out = self.activation3(x)\n",
        "    return out\n",
        "\n",
        "  def training_step(self, batch):\n",
        "    images, labels = batch \n",
        "    out = self(images)                  # Generate predictions\n",
        "    loss = F.cross_entropy(out,labels) # Calculate loss\n",
        "    return loss\n",
        "   # acc = accuracy(out,labels)\n",
        "   # return {'train_loss':loss.detach(), 'train_acc':acc.detach()}\n",
        "  \n",
        "  def train_step(self,batch):\n",
        "    images,labels = batch\n",
        "    out = self(images)\n",
        "    loss = F.cross_entropy(out,labels)\n",
        "    acc = accuracy(out,labels)\n",
        "    return {'train_loss':loss.detach(), 'train_acc':acc.detach()}\n",
        "  \n",
        "  def validation_step(self, batch):\n",
        "    images, labels = batch \n",
        "    out = self(images)                    # Generate predictions\n",
        "    loss = F.cross_entropy(out,labels)   # Calculate loss\n",
        "    acc = accuracy(out, labels)           # Calculate accuracy\n",
        "    return {'val_loss': loss.detach(), 'val_acc': acc.detach()}\n",
        "\n",
        "  def train_epoch_end(self,outputs):\n",
        "    batch_losses =[x['train_loss'] for x in outputs]\n",
        "    epoch_loss = torch.stack(batch_losses).mean()\n",
        "    batch_accs = [x['train_acc'] for x in outputs]\n",
        "    epoch_acc = torch.stack(batch_accs).mean()\n",
        "    return {'train_loss':epoch_loss.item(),'train_acc': epoch_acc.item()}\n",
        "        \n",
        "  def validation_epoch_end(self, outputs):\n",
        "    batch_losses = [x['val_loss'] for x in outputs]\n",
        "    epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "    batch_accs = [x['val_acc'] for x in outputs]\n",
        "    epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "    return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    \n",
        "  def epoch_end_val(self, epoch, result):\n",
        "    print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n",
        "  def epoch_end_train(self,epoch,result):\n",
        "    print(\"Epoch [{}], train_loss: {:.4f}, train_acc: {:.4f}\".format(epoch, result['train_loss'], result['train_acc']))\n",
        "\n",
        "  \n",
        "\n",
        "model = MnistModel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mDMUHq8bQ5F",
        "outputId": "6e4cdfe1-17a1-4455-a720-a818bcaf80d7"
      },
      "source": [
        "\n",
        "print(model.linear1)\n",
        "print(model.linear2)\n",
        "print(model.linear3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear(in_features=784, out_features=128, bias=True)\n",
            "Linear(in_features=128, out_features=64, bias=True)\n",
            "Linear(in_features=64, out_features=10, bias=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxSLypv2LOD-"
      },
      "source": [
        "#print(model.linear3.weight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ouYwuNX2Zn9"
      },
      "source": [
        "def accuracy(outputs, labels):\n",
        "  _, preds = torch.max(outputs, dim=1)\n",
        "  return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "  \n",
        "def customize_one_hot_encoder(y):\n",
        "  one_hot=F.one_hot(y,num_classes=output_size).float()\n",
        "  one_hot[one_hot==0.0]=-1.0\n",
        "  return one_hot\n",
        "\n",
        "def Exponential_Loss(y_true,y_pred):\n",
        "  y_true = customize_one_hot_encoder(y_true)\n",
        "  Loss = torch.sum(torch.exp(-(torch.multiply(y_true,y_pred))))\n",
        "  return Loss/len(y_true)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP6LC3f3CGT0"
      },
      "source": [
        "def evaluate_validation(model, val_loader):\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def evaluate_training(model,train_loader):\n",
        "  outputs = [model.train_step(batch) for batch in train_loader]\n",
        "  return model.train_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    losses = []\n",
        "    history_val =[]\n",
        "    history_train= []\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        result_train = evaluate_training(model,train_loader)\n",
        "        model.epoch_end_train(epoch,result_train)\n",
        "        history_train.append(result_train)\n",
        "        # Validation phase\n",
        "        losses.append(loss)\n",
        "        result_val = evaluate_validation(model, val_loader)\n",
        "        model.epoch_end_val(epoch, result_val)\n",
        "        history_val.append(result_val)\n",
        "        history = [history_train, history_val]\n",
        "    return history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ0-hRDuCS-r"
      },
      "source": [
        "#evaluate_validation(model,valloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KuKufSoDdzL",
        "outputId": "dee8dec1-2f9c-44a6-d19a-e36e3a065606"
      },
      "source": [
        "history = fit(11,0.1,model,trainloader,valloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [0], train_loss: 1.5031, train_acc: 0.9610\n",
            "Epoch [0], val_loss: 1.5063, val_acc: 0.9577\n",
            "Epoch [1], train_loss: 1.5058, train_acc: 0.9582\n",
            "Epoch [1], val_loss: 1.5084, val_acc: 0.9554\n",
            "Epoch [2], train_loss: 1.5258, train_acc: 0.9392\n",
            "Epoch [2], val_loss: 1.5270, val_acc: 0.9369\n",
            "Epoch [3], train_loss: 1.4971, train_acc: 0.9666\n",
            "Epoch [3], val_loss: 1.5028, val_acc: 0.9605\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "2fRvXhVaRN_R",
        "outputId": "6b62f3d6-0381-4a72-86c4-8dd0a88dac91"
      },
      "source": [
        "val_accuracies = [r['val_acc'] for r in history[1]]\n",
        "train_accuracies = [s['train_acc'] for s in history[0]]\n",
        "plt.plot(train_accuracies)\n",
        "plt.plot(val_accuracies)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend([\"Train_Accuracy\",\"Val_Accuracy\"])\n",
        "plt.title('Accuracy vs. No. of epochs');\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-06b5718b2c6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy vs. No. of epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nL9YdlGjbDZ"
      },
      "source": [
        "val_losses = [r['val_loss'] for r in history[1]]\n",
        "train_losses = [s['train_loss'] for s in history[0]]\n",
        "plt.plot(train_losses)\n",
        "plt.plot(val_losses)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend([\"Train_loss\", \"Val_loss\"])\n",
        "plt.title('Loss vs No. of epochs');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ct1Amtl8yrNw"
      },
      "source": [
        "def predict_image(img, model):\n",
        "    xb = img.unsqueeze(0)\n",
        "    yb = model(xb)\n",
        "    _, preds  = torch.max(yb, dim=1)\n",
        "    return preds[0].item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uW3tggnZSOx"
      },
      "source": [
        "def correct_pred(img,label):\n",
        "  if label == predict_image(img,model):\n",
        "    str = \"correct\"    \n",
        "  else:\n",
        "    str = \"incorrect\"\n",
        "  return str"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QO_DsnL9RFpD"
      },
      "source": [
        "for i in range(1000):\n",
        "  img, label = testset[i]\n",
        "  #plt.imshow(img[], cmap='gray')\n",
        "  output = correct_pred(img,label)\n",
        "  print('Label:', label, ', Predicted:', predict_image(img, model) ,',Status:',output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_Gi77Sb_fHj"
      },
      "source": [
        "def count_correct_pred(test_set):\n",
        "  correct = 0\n",
        "  incorrect = 0\n",
        "  for i in range(1000):\n",
        "    img, label = test_set[i]\n",
        "    if label == predict_image(img,model):\n",
        "      correct +=1\n",
        "    else:\n",
        "      incorrect +=1\n",
        "  return correct,incorrect\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIiXKoHRA1Ym"
      },
      "source": [
        "cor, incor = count_correct_pred(testset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77-wii5AEwH4"
      },
      "source": [
        "print(cor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omnZ9SdIExdk"
      },
      "source": [
        "print(incor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOeUgBoxEzTG"
      },
      "source": [
        "print(cor+incor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_wUBe_lE3Ht"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}